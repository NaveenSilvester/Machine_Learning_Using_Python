{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b37ca9a-5c0b-4f07-94b4-8e322b676074",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb7dd0c-aec4-468d-bd5e-335b64efd0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2f8755c-18e6-446d-8fda-aee4671f3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings ('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86afd7d8-3772-4e55-9fc1-69e55297d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv(\"Advertising.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff59d5c2-1045-45b2-980d-5bdbc5b77ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0           1  230.1   37.8       69.2   22.1\n",
       "1           2   44.5   39.3       45.1   10.4\n",
       "2           3   17.2   45.9       69.3    9.3\n",
       "3           4  151.5   41.3       58.5   18.5\n",
       "4           5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85eb1de4-eb8a-4359-a99a-b29dc1ce0813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  200 non-null    int64  \n",
      " 1   TV          200 non-null    float64\n",
      " 2   Radio       200 non-null    float64\n",
      " 3   Newspaper   200 non-null    float64\n",
      " 4   Sales       200 non-null    float64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70db6c9e-a6ca-4e05-8223-dcf8c8e9ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sales_df[['TV','Radio','Newspaper']]\n",
    "Y= sales_df.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f782bc2e-0ae3-4253-984f-ac35d5a23a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X and Y\n",
    "Y= np.array ( (Y - Y.mean())/Y.std())\n",
    "X = X.apply(lambda rec: (rec- rec.mean()) / rec.std(), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2371e6ee-2635-462b-8bc0-04ebd1d23e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method-1: Random initialization of the Bias and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf24741e-9f6d-43c9-bd33-4e9e86136dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def initialize (dim):\n",
    "    np.random.seed (seed=42)\n",
    "    random.seed(42)\n",
    "    b = random.random()\n",
    "    w = np.random.rand(dim)\n",
    "    return b, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a758c27f-217d-402d-9165-d80be8877315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias :  0.6394267984578837 Weights :  [0.37454012 0.95071431 0.73199394]\n"
     ]
    }
   ],
   "source": [
    "# To initialize the bias and 3 weights, as we have three input variables TV, Radio, and Newspaper, we can invoke the initialize() method as follows\n",
    "b, w = initialize(3)\n",
    "print (\"Bias : \", b, \"Weights : \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3162ef05-2de2-4a7f-8060-87e6c9ac1f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method-2: Predict Y values from the Bias and Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5baade02-aa41-4d71-a713-11b9f82c54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_Y (b,w, X):\n",
    "    return b + np.matmul(X,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89883037-388d-40c1-9c67-3ba961f65633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3.231496\n",
       "1    1.707849\n",
       "2    2.824761\n",
       "3    2.753090\n",
       "4    0.924486\n",
       "5    3.171365\n",
       "6    0.622344\n",
       "7   -0.349354\n",
       "8   -2.313095\n",
       "9   -0.768030\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now calculate the predicted values after initializing bias and weights\n",
    "b, w = initialize (3)\n",
    "Y_hat = predict_Y(b, w, X)\n",
    "Y_hat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4ebde-c6d2-4ec9-b0a6-50258104956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method-3 : Calculate the Cost Function - MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63153b-f97a-4b9c-9189-b3778802b820",
   "metadata": {},
   "source": [
    "Sure! Let's dive into these three popular ensemble learning techniques: Random Forest, AdaBoost, and Gradient Boosting.\n",
    "\n",
    "### Random Forest\n",
    "**Random Forest** is an ensemble method that builds multiple decision trees and merges them together to get a more accurate and stable prediction. It works by creating a 'forest' of trees, each trained on a random subset of the data and features.\n",
    "\n",
    "**Example**: Imagine you want to predict whether a person will buy a product based on their age, income, and browsing history. A Random Forest model would create multiple decision trees, each making its own prediction. The final prediction is the majority vote of all the trees.\n",
    "\n",
    "### AdaBoost (Adaptive Boosting)\n",
    "**AdaBoost** is a boosting technique that combines multiple weak classifiers to create a strong classifier. It works by training classifiers sequentially, each trying to correct the errors of its predecessor. The classifiers are weighted based on their accuracy, and more weight is given to misclassified instances.\n",
    "\n",
    "**Example**: Suppose you are classifying emails as spam or not spam. AdaBoost would start with a simple classifier, like a decision stump (a tree with one split). It then adjusts the weights of the misclassified emails and trains another classifier. This process repeats, with each new classifier focusing more on the difficult cases.\n",
    "\n",
    "### Gradient Boosting\n",
    "**Gradient Boosting** is another boosting technique that builds models sequentially. Each new model corrects the errors of the combined ensemble of previous models. It uses gradient descent to minimize the loss function, making it a powerful method for both classification and regression tasks.\n",
    "\n",
    "**Example**: If you are predicting house prices, Gradient Boosting would start with a simple model and iteratively add new models that reduce the prediction error. Each new model is trained to correct the residual errors of the combined previous models.\n",
    "\n",
    "### Summary\n",
    "- **Random Forest**: Builds multiple decision trees and averages their predictions.\n",
    "- **AdaBoost**: Sequentially trains classifiers, focusing on misclassified instances.\n",
    "- **Gradient Boosting**: Sequentially trains models to correct errors using gradient descent.\n",
    "\n",
    "These techniques are widely used in machine learning due to their ability to improve model accuracy and robustness¹²³.\n",
    "\n",
    "Would you like to see a code example for any of these methods?\n",
    "\n",
    "Source: Conversation with Copilot, 5/11/2024\n",
    "(1) 1.11. Ensembles: Gradient boosting, random forests, bagging, voting .... https://scikit-learn.org/stable/modules/ensemble.html.\n",
    "(2) Google Colab. https://colab.research.google.com/github/ruslanmv/Multiclass_Classification_with_Ensemble_Models/blob/master/Multiclass_Classification_with_Ensemble_Models_colab.ipynb.\n",
    "(3) AdaBoost and Gradient Boost - Analytics Vidhya. https://www.analyticsvidhya.com/blog/2020/10/adaboost-and-gradient-boost-comparitive-study-between-2-popular-ensemble-model-techniques/.\n",
    "(4) Boosting and AdaBoost for Machine Learning. https://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/.\n",
    "(5) 1.11. Ensembles: Gradient boosting, random forests, bagging, voting .... https://scikit-learn.org/dev/modules/ensemble.html.\n",
    "(6) How to Develop a Gradient Boosting Machine Ensemble in Python. https://machinelearningmastery.com/gradient-boosting-machine-ensemble-in-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3be659a-032a-42f1-ba39-3005528e4687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
